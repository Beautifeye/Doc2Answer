{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_utils.google import Create_Service\n",
    "from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload\n",
    "import io\n",
    "import os\n",
    "import socket\n",
    "socket.setdefaulttimeout(30000)\n",
    "import time\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rawpy\n",
    "import imageio\n",
    "import shutil\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_SECRET_FILE = 'client_secret.json'\n",
    "API_NAME = 'drive'\n",
    "API_VERSION = 'v3'\n",
    "SCOPES = [\n",
    "    'https://www.googleapis.com/auth/drive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_secret.json-drive-v3-(['https://www.googleapis.com/auth/drive'],)\n",
      "['https://www.googleapis.com/auth/drive']\n",
      "drive service created successfully\n"
     ]
    }
   ],
   "source": [
    "service = Create_Service(CLIENT_SECRET_FILE, API_NAME, API_VERSION, SCOPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_service = service.files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ARW2JPG(path, dst_folder):\n",
    "    fn = path.split('/')[-1][:-4]+'.jpg'\n",
    "    dst_path = os.path.join(dst_folder, fn)\n",
    "    with rawpy.imread(path) as raw:\n",
    "        rgb = raw.postprocess(use_camera_wb=True)\n",
    "\n",
    "    rgb1 = rgb[:,:,:1].copy()\n",
    "    rgb2 = rgb[:,:,1:2].copy()\n",
    "    rgb3 = rgb[:,:,2:3].copy()\n",
    "\n",
    "    rgb_f = np.concatenate([rgb1, rgb2, rgb3], axis=2)\n",
    "    plt.imsave(dst_path, rgb_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://drive.google.com/file/d/1JaYF-Ep-C6b5X01_e9tFRzFgRXMJQYQ7/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "folder_id = '1EUMPbhZY6eKwAfgAO8TvFxlvXVsG3YzM'\n",
    "res = files_service.list(corpus=\"user\",\n",
    "                   q=f'\"{folder_id}\" in parents',\n",
    "                   fields=\"nextPageToken, files(id, name)\",\n",
    "                   supportsAllDrives=True, \n",
    "                   includeItemsFromAllDrives=True).execute()\n",
    "files = files + res['files'] \n",
    "page_token = res.get('nextPageToken', False)\n",
    "\n",
    "while page_token:\n",
    "    res = files_service.list(corpus=\"user\",\n",
    "                    q=f'\"{folder_id}\" in parents',\n",
    "                    fields=\"nextPageToken, files(id, name)\",\n",
    "                    pageToken=page_token,\n",
    "                    supportsAllDrives=True, \n",
    "                    includeItemsFromAllDrives=True).execute()\n",
    "    files = files + res['files'] \n",
    "    page_token = res.get('nextPageToken', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1429"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = sorted(files, key=lambda x: x['name'])\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    request = files_service.get_media(fileId=file['id'])\n",
    "    fn = file['name']\n",
    "    path = '/home/ubuntu/storage/Doc2Answer/download_from_drive/data/ProcessedCards/ProcessedInnerLabels/'+fn\n",
    "    if not os.path.isfile(path):\n",
    "        fh = io.FileIO(path, \"wb\")\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Download from Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "folder_id = '1RQGwFKxRrWRm89fEQ65sbZrseOv8talR'\n",
    "res = files_service.list(corpus=\"user\",\n",
    "                   q=f'\"{folder_id}\" in parents',\n",
    "                   fields=\"nextPageToken, files(id, name)\",\n",
    "                   supportsAllDrives=True, \n",
    "                   includeItemsFromAllDrives=True).execute()\n",
    "files = files + res['files'] \n",
    "page_token = res.get('nextPageToken', False)\n",
    "\n",
    "while page_token:\n",
    "    res = files_service.list(corpus=\"user\",\n",
    "                    q=f'\"{folder_id}\" in parents',\n",
    "                    fields=\"nextPageToken, files(id, name)\",\n",
    "                    pageToken=page_token,\n",
    "                    supportsAllDrives=True, \n",
    "                    includeItemsFromAllDrives=True).execute()\n",
    "    files = files + res['files'] \n",
    "    page_token = res.get('nextPageToken', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('extracted_archives.npy'):\n",
    "    extracted_file_ids = np.load('extracted_archives.npy').tolist()\n",
    "else:\n",
    "    extracted_file_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = sorted(files, key=lambda x: x['name'])\n",
    "files = [file for file in files if file['id'] not in extracted_file_ids and file['name'].startswith('Cards')]\n",
    "\n",
    "len(extracted_file_ids), len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def convert_cards(card_folder):\n",
    "    fnms = [fn for fn in os.listdir(card_folder) if not fn.endswith('.ipynb_checkpoints')]\n",
    "    for fn in fnms:\n",
    "        filepath = os.path.join(card_folder, fn)\n",
    "        if fn.endswith('arw'):\n",
    "            convert_ARW2JPG(filepath, card_dst_folder)\n",
    "        else:\n",
    "            shutil.copy(filepath, os.path.join(card_dst_folder, fn))\n",
    "            \n",
    "def convert_O7(o7_folder):\n",
    "    fnms = [fn for fn in os.listdir(o7_folder) if not fn.endswith('.ipynb_checkpoints')]\n",
    "    for fn in fnms:\n",
    "        filepath = os.path.join(o7_folder, fn)\n",
    "        if fn.endswith('arw'):\n",
    "            convert_ARW2JPG(filepath, o7_dst_folder)\n",
    "        else:\n",
    "            shutil.copy(filepath, os.path.join(o7_dst_folder, fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Cards 3_20.03.2021-20210817T102617Z-010.zip\n",
      "9 2\n",
      "./data/Cards 3_20.03.2021-20210817T102617Z-011.zip\n",
      "8 3\n",
      "./data/Cards 3_20.03.2021-20210817T102617Z-012.zip\n",
      "7 2\n",
      "./data/Cards 3_20.03.2021-20210817T102617Z-013.zip\n",
      "5 6\n",
      "./data/Cards 3_20.03.2021-20210817T102617Z-014.zip\n",
      "6 6\n",
      "./data/Cards 3_20.03.2021-20210817T102617Z-015.zip\n",
      "6 3\n",
      "./data/Cards 3_20.03.2021-20210817T102617Z-016.zip\n",
      "7 3\n",
      "./data/Cards 3_20.03.2021-20210817T102617Z-017.zip\n",
      "5 1\n",
      "./data/Cards 3_20.03.2021-20210817T102617Z-018.zip\n",
      "2 0\n",
      "./data/Cards 4_9.04.2021-20210830T101756Z-001.zip\n",
      "4 10\n",
      "./data/Cards 4_9.04.2021-20210830T101756Z-002.zip\n",
      "9 0\n",
      "./data/Cards 4_9.04.2021-20210830T101756Z-003.zip\n",
      "9 3\n",
      "./data/Cards 4_9.04.2021-20210830T101756Z-004.zip\n",
      "10 3\n",
      "./data/Cards 5_15.04.2021-20210830T102505Z-001.zip\n",
      "6 7\n",
      "./data/Cards 5_15.04.2021-20210830T102505Z-002.zip\n",
      "5 1\n",
      "./data/Cards 6_15.04.2021-20210830T102722Z-001.zip\n",
      "7 7\n",
      "./data/Cards 6_15.04.2021-20210830T102722Z-002.zip\n",
      "10 4\n",
      "./data/Cards 6_15.04.2021-20210830T102722Z-003.zip\n",
      "8 0\n",
      "./data/Cards 7_12.05.2021-20210830T104112Z-001.zip\n",
      "8 9\n",
      "./data/Cards 7_12.05.2021-20210830T104112Z-002.zip\n",
      "11 5\n",
      "./data/Cards 7_12.05.2021-20210830T104112Z-003.zip\n",
      "9 6\n",
      "./data/Cards 7_12.05.2021-20210830T104112Z-004.zip\n",
      "13 6\n",
      "./data/Cards 7_12.05.2021-20210830T104112Z-005.zip\n",
      "19 4\n",
      "./data/Cards 7_12.05.2021-20210830T104112Z-006.zip\n",
      "10 0\n",
      "./data/Cards 8_12.05.2021-20210830T112751Z-001.zip\n",
      "6 12\n",
      "./data/Cards 8_12.05.2021-20210830T112751Z-002.zip\n",
      "7 6\n",
      "./data/Cards 8_12.05.2021-20210830T112751Z-003.zip\n",
      "6 3\n",
      "./data/Cards 8_12.05.2021-20210830T112751Z-004.zip\n",
      "9 3\n",
      "./data/Cards 8_12.05.2021-20210830T112751Z-005.zip\n",
      "3 0\n",
      "./data/Cards_9_8.06.2021-20210830T120111Z-001.zip\n",
      "7 12\n",
      "./data/Cards_9_8.06.2021-20210830T120111Z-002.zip\n",
      "8 0\n",
      "./data/Cards_9_8.06.2021-20210830T120111Z-003.zip\n",
      "6 6\n",
      "./data/Cards_9_8.06.2021-20210830T120111Z-004.zip\n",
      "8 9\n",
      "./data/Cards_9_8.06.2021-20210830T120111Z-005.zip\n",
      "9 2\n",
      "./data/Cards_9_8.06.2021-20210830T120111Z-006.zip\n",
      "10 4\n",
      "./data/Cards_9_8.06.2021-20210830T120111Z-007.zip\n",
      "6 1\n",
      "./data/Cards_9_8.06.2021-20210830T120111Z-008.zip\n",
      "3 0\n"
     ]
    }
   ],
   "source": [
    "zip_folder = './data/'\n",
    "\n",
    "data_folder = '/home/ubuntu/storage/Doc2Answer/download_from_drive/data'\n",
    "chunk_folders = [fn for fn in os.listdir(data_folder) if 'Cards ' in fn]\n",
    "card_dst_folder = os.path.join(data_folder, 'Cards')\n",
    "o7_dst_folder = os.path.join(data_folder, 'O7')\n",
    "\n",
    "for file in files:\n",
    "    request = files_service.get_media(fileId=file['id'])\n",
    "    fn = file['name']\n",
    "    zip_path = os.path.join(zip_folder, fn)\n",
    "    print(zip_path)\n",
    "    if not os.path.isfile(zip_path):\n",
    "        fh = io.FileIO(zip_path, \"wb\")\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()\n",
    "    \n",
    "    tmp_path = os.path.join(data_folder, 'tmp')\n",
    "    chunk_path = os.path.join(data_folder, 'chunk')\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(tmp_path)\n",
    "    shutil.move(os.path.join(tmp_path, os.listdir(tmp_path)[0]), chunk_path)\n",
    "    shutil.rmtree(tmp_path)\n",
    "\n",
    "    cards_folders = [os.path.join(chunk_path, fn) for fn in os.listdir(chunk_path) \n",
    "                     if '_o7' not in fn.lower() and not fn.endswith('.ipynb_checkpoints') and os.path.isdir(os.path.join(chunk_path, fn))]\n",
    "    o7_folders = [os.path.join(chunk_path, fn) for fn in os.listdir(chunk_path)\n",
    "                  if '_o7' in fn.lower() and not fn.endswith('.ipynb_checkpoints') and os.path.isdir(os.path.join(chunk_path, fn))]\n",
    "    print(len(cards_folders), len(o7_folders))\n",
    "    os.makedirs(card_dst_folder, exist_ok=True)\n",
    "    os.makedirs(o7_dst_folder, exist_ok=True)\n",
    "    \n",
    "    with Pool() as p:\n",
    "        p.map(convert_cards, cards_folders)\n",
    "    with Pool() as p:\n",
    "        p.map(convert_O7, o7_folders)\n",
    "\n",
    "    shutil.rmtree(chunk_path)\n",
    "    os.remove(zip_path)\n",
    "    extracted_file_ids.append(file['id'])\n",
    "    np.save('extracted_archives', extracted_file_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Zip FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_metadata = {'name': 'ProcessedInnerCards.zip', 'parents':['1b1UvUbKH1X5EXKYuEGbagfGT-9pQaypD'], 'supportsAllDrives':True,}\n",
    "# driveId: \"0AFiiwdVdxetuUk9PVA\"\n",
    "media = MediaFileUpload(\n",
    "    '/home/ubuntu/clubbertv_storage/ProcessedInnerCards.zip',\n",
    "    mimetype='application/zip',\n",
    "    resumable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ID: 1MxtNbReoVi9I-geRuXpghVcXE48gCaNf\n"
     ]
    }
   ],
   "source": [
    "file = files_service.create(\n",
    "    body=file_metadata,\n",
    "    media_body=media,\n",
    "    fields='id',\n",
    "    supportsAllDrives=True,\n",
    "    supportsTeamDrives=True).execute()\n",
    "print('File ID: %s' % file.get('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = '/home/ubuntu/storage/Doc2Answer/download_from_drive/data/ProcessedO7/'\n",
    "for fn in os.listdir(FOLDER):\n",
    "    file_metadata = {'name': fn, 'parents':['1fYnlu8HZwlxv0twOBeliLDn_qmi0RH6y'], 'supportsAllDrives':True,}\n",
    "    media = MediaFileUpload(\n",
    "        os.path.join(FOLDER, fn),\n",
    "        mimetype='image/jpeg',\n",
    "        resumable=True)\n",
    "    file = files_service.create(\n",
    "    body=file_metadata,\n",
    "    media_body=media,\n",
    "    fields='id',\n",
    "    supportsAllDrives=True,\n",
    "    supportsTeamDrives=True).execute()\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_on_drive(file, parent_id, mimetype):\n",
    "    fn = file.split('/')[-1]\n",
    "    file_metadata = {'name': fn, 'parents':[parent_id], 'supportsAllDrives':True,}\n",
    "    media = MediaFileUpload(\n",
    "        file,\n",
    "        mimetype=mimetype,\n",
    "        resumable=True)\n",
    "    drive_file = files_service.create(\n",
    "        body=file_metadata,\n",
    "        media_body=media,\n",
    "        fields='id',\n",
    "        supportsAllDrives=True,\n",
    "        supportsTeamDrives=True).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_on_drive(folder, parent_id):\n",
    "    folder_name = folder.split('/')[-1]\n",
    "    file_metadata = {\n",
    "    'name' : folder_name,\n",
    "    'parents' : [parent_id],\n",
    "    'mimeType' : 'application/vnd.google-apps.folder'\n",
    "    }\n",
    "\n",
    "    file = files_service.create(body=file_metadata,\n",
    "                                    fields='id').execute()\n",
    "    return file['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def is_interesting(path):\n",
    "    paths = [path]\n",
    "    new_paths = [os.path.join(path, fn) for fn in os.listdir(path) if os.path.isdir(os.path.join(path, fn)) and not '.' in fn]\n",
    "    new_files = [os.path.join(path, fn) for fn in os.listdir(path) if os.path.isfile(os.path.join(path, fn))]\n",
    "    if len(new_paths) ==0 and len(new_files)==0:\n",
    "        return False\n",
    "    if len(new_paths) == 0:\n",
    "        return max([\n",
    "            max([fn.endswith(f) for f in ['.py','ipynb','.md','.json']]) for fn in new_files])\n",
    "    if len(new_files) == 0:\n",
    "        return max([is_interesting(p) for p in new_paths])\n",
    "    else:\n",
    "        return max(\n",
    "            max([max([fn.endswith(f) for f in ['.py','ipynb','.md','.json']]) for fn in new_files]),\n",
    "            max([is_interesting(p) for p in new_paths]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_FOLDER = '/home/ubuntu/'\n",
    "folders = [START_FOLDER]\n",
    "BAD_FOLDERS = ['libiconv-1.11', 'opencv', 'opencv_contrib', 'seaborn-data','tools', 'volume/dump']\n",
    "folder_ids = ['1b1UvUbKH1X5EXKYuEGbagfGT-9pQaypD']\n",
    "while len(folders) > 0:\n",
    "    folder = folders[0]\n",
    "    folders = folders[1:]\n",
    "    folder_id = folder_ids[0]\n",
    "    folder_ids = folder_ids[1:]\n",
    "    folder_files = [os.path.join(folder, fn) for fn in os.listdir(folder)\n",
    "                    if os.path.isfile(os.path.join(folder, fn)) and\n",
    "                    (fn.endswith('.py') or fn.endswith('.ipynb') or fn.endswith('.md') or fn.endswith('.json'))]\n",
    "    folder_folders = [os.path.join(folder, fn) for fn in os.listdir(folder)\n",
    "                      if os.path.isdir(os.path.join(folder, fn)) and 'anaconda' not in fn and not fn.startswith('.') and not '.' in fn and\n",
    "                      is_interesting(os.path.join(folder, fn))\n",
    "                      and os.path.join(folder, fn) not in [os.path.join(START_FOLDER, ff) for ff in BAD_FOLDERS]]\n",
    "    folders = folders + folder_folders\n",
    "    \n",
    "    for folder_file in folder_files:\n",
    "        mimetype = 'text/plain'\n",
    "        upload_on_drive(folder_file, folder_id, mimetype)\n",
    "        \n",
    "    for new_folder in folder_folders:\n",
    "        new_folder_id = create_folder_on_drive(new_folder, folder_id)\n",
    "        folder_ids = folder_ids + [new_folder_id] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir( '/home/ubuntu/data/terminal/backup_data/snapshot/diagnostic.data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
