{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./faster_RCNN/')\n",
    "\n",
    "from H_dataset_class import HDataset\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from engine import evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        # during training, randomly flip the training images\n",
    "        # and ground-truth for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle('test_df.pkl')\n",
    "test_dataset = HDataset(data_df=test_df, transforms=get_transform(train=True))\n",
    "\n",
    "def inference_collate(batch):\n",
    "    data = torch.cat([item[0][None, :] for item in batch], dim=0)\n",
    "    return data\n",
    "    \n",
    "data_loader_test = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=8,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=4,\n",
    "                                               collate_fn=inference_collate,\n",
    "                                               pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# checkpoint_path = 'checkpoints/checkpoint-09'\n",
    "\n",
    "# model = torch.load('trained_models/checkpoint-10.pt')\n",
    "# model.to(device)\n",
    "\n",
    "# evaluate(model=model,\n",
    "#          data_loader=data_loader_test,\n",
    "#          device=device\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(model, data_loader, device):\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preprocess = get_transform(train=False)\n",
    "    \n",
    "    preds = []\n",
    "    for i, X_batch in enumerate(data_loader):\n",
    "        X_batch_GPU = X_batch.to(device)\n",
    "        preds += model(X_batch_GPU)\n",
    "    \n",
    "    return preds\n",
    "        \n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "checkpoint_path = 'trained_models/checkpoint-10.pt'\n",
    "\n",
    "model = torch.load(checkpoint_path)\n",
    "model.to(device)\n",
    "preds = inference(model, data_loader_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'out'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "for i, pred in enumerate(preds):\n",
    "    score = pred['scores'].cpu().numpy()[0]\n",
    "    x1, y1, x2, y2 = pred['boxes'].cpu().numpy()[0].astype(int)\n",
    "    im = cv2.imread(test_df.loc[i]['path'])\n",
    "    cv2.rectangle(im, (x1, y1), (x2, y2), (23,46,111), 2)\n",
    "    cv2.imwrite(os.path.join(out_dir, str(i).zfill(3) + '_' + str(score) + '.jpg'), im)\n",
    "    \n",
    "# for i, row in test_df.iterrows():\n",
    "#     im = cv2.imread(row['path'])\n",
    "#     x1, y1, x2, y2 = row['points']\n",
    "#     cv2.rectangle(im, (x1, y1), (x2, y2), (23,46,111), 2)\n",
    "#     cv2.imwrite(os.path.join(out_dir, str(i).zfill(3) + '_' + str(row['score']) + '.jpg'), im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('./faster_RCNN/')\n",
    "import transforms as T\n",
    "t1 = T.DataAugmentation('hue', -0.1, 0.1)\n",
    "t2 = T.DataAugmentation('contrast', 0.5, 0.3)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(30,10))\n",
    "im = Image.open('/home/ubuntu/additional_volume/clubbertv_data/H-detection-annoattated-data/filtered_samples/img/img_00002521.jpg')\n",
    "axes[0].imshow(im)\n",
    "axes[0].axis('off')\n",
    "\n",
    "print(type(im))\n",
    "\n",
    "im = t1(im)\n",
    "axes[1].imshow(im)\n",
    "axes[1].axis('off')\n",
    "\n",
    "im = t2(im)\n",
    "axes[2].imshow(im)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_object_detection_fine_tuning)",
   "language": "python",
   "name": "conda_object_detection_fine_tuning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
