{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../stamp_detection/faster_RCNN/')\n",
    "sys.path.append('../stamp_detection//')\n",
    "from stamp_dataset_class import StampDataset\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, fasterrcnn_resnet50_fpn\n",
    "\n",
    "from engine import evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import albumentations as A\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def detection_inference(model, data_loader, device):\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preprocess = get_transform(train=False)\n",
    "    \n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for i, (X_i, Y_i) in enumerate(tqdm(test_dataset)):\n",
    "            X_i_GPU = X_i.to(device)[None, :]\n",
    "            preds += [{k: v.cpu().detach().numpy() for k,v in res.items()} for res in model(X_i_GPU)]\n",
    "            del X_i_GPU\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load detection\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "checkpoint_path = '../best_models_to_date/stamp_detection/FasterRCNN-checkpoint.pt'#'trained_models_v4/checkpoint_v4-07.pt'\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device), strict=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print('Model loaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50 \n",
    "\n",
    "\n",
    "class Siamese(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Siamese, self).__init__()\n",
    "\n",
    "        self.feature_extractor = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)\n",
    "        self.feature_extractor.classifier[1] = nn.Conv2d(512, 2048, kernel_size=(1,1), stride=(1,1))\n",
    "        self.linear = nn.Sequential(nn.Linear(2048, 2048), nn.Sigmoid())\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = (self.linear(x) * 2.) - 1\n",
    "        x = x / (torch.norm(x, dim=1, keepdim=True) + 1e-6)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x_pair):\n",
    "        x1, x2 = x_pair[:,:3], x_pair[:,3:]\n",
    "        out1 = self.forward_one(x1)\n",
    "        out2 = self.forward_one(x2)\n",
    "        sim = (torch.sum(torch.mul(out1, out2), dim=1) + 1) / 2.\n",
    "        return sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = Siamese()\n",
    "checkpoint = torch.load('stamp_classification/SiameseStampNet-checkpoint.pt', map_location=device)\n",
    "siamese_model.load_state_dict(checkpoint)\n",
    "siamese_model.to(device)\n",
    "siamese_model.eval()\n",
    "print('Model successfully loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp_det_df = pd.read_pickle(\"../stamp_detection/test_v4_df.pkl\")\n",
    "img_path = sorted(stamp_det_df.path.unique())[23]\n",
    "plt.figure(figsize=(10,10)); plt.imshow(plt.imread(img_path)); plt.axis(\"off\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_card_df = stamp_det_df.query(\"path == @img_path\")\n",
    "img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "for _, row in single_card_df.iterrows():\n",
    "    x1, y1, x2, y2 = row.points\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,0), 8)\n",
    "    \n",
    "plt.figure(figsize=(10,10)); plt.imshow(img); plt.axis(\"off\"); plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'path':[img_path], 'points':[[]]})\n",
    "\n",
    "dummy_transforms = T.Compose([T.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms as T\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = StampDataset(data, transforms=dummy_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gpu = df[0][0].to(device)[None]\n",
    "with torch.no_grad():\n",
    "    preds = [{k: v.cpu().detach().numpy() for k,v in res.items()} for res in model(X_gpu)]\n",
    "del X_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = np.array([preds[0]['boxes'][i] for i in range(len(preds[0]['boxes'])) if preds[0]['scores'][i]>0.5])\n",
    "boxes = np.round(boxes).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_transforms = A.Compose([\n",
    "    A.Resize(128, 128)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesses(img, boxes, show=False):\n",
    "    patches = None\n",
    "    img_patches = []\n",
    "    for box in boxes:\n",
    "        patch = img[box[1]:box[3], box[0]:box[2]].copy().astype(np.float32) / 255.\n",
    "        patch = dummy_transforms(image=patch)['image']\n",
    "        if show:\n",
    "            img_patches.append(patch.copy())\n",
    "        patch = ToTensor()(patch)[None, :]\n",
    "        if patches is None:\n",
    "            patches = patch\n",
    "        else:\n",
    "            patches = torch.cat([patches, patch], dim=0)\n",
    "    if show:\n",
    "        return patches, img_patches\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "patches = preprocesses(img, boxes)\n",
    "\n",
    "with torch.no_grad():\n",
    "    patches = patches.to(device)\n",
    "    vecs = siamese_model.forward_one(patches).detach().cpu().numpy()\n",
    "    del patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_vecs = pkl.load(open('./stamp_classification/template_vecs.pkl','rb+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for i in range(len(vecs)):\n",
    "    scores_i = np.sum(vecs[i]* template_vecs, axis=1).ravel()\n",
    "    class_i = np.argmax(scores_i)\n",
    "    classes.append(class_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = list(mpl.colors.BASE_COLORS.keys())\n",
    "class2color = {np.unique(classes)[i]: colors[i] for i in range(len(np.unique(classes)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "pca_vecs = PCA(2).fit_transform(vecs) + (np.random.random(size=(len(vecs),2))-.5) * 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(pca_vecs[:,0], pca_vecs[:,1], color=[class2color[classes[i]] for i in range(len(vecs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = './classified_stamps/out'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "images = [img]\n",
    "for k, pred in enumerate(preds):\n",
    "    im = images[k].copy()\n",
    "    for i, ((x1, y1, x2, y2), score) in enumerate(zip(boxes, pred['scores'])):\n",
    "        if score >.3:\n",
    "            color = tuple([int(c) for c in (np.array(mpl.colors.BASE_COLORS[class2color[classes[i]]]) * 255).astype(np.int)])\n",
    "            cv2.rectangle(im, (int(x1), int(y1)), (int(x2), int(y2)), color, 10)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(os.path.join(out_dir, img_path.split('/')[-1][:-4] + '_classified' + '.jpg'), im)\n",
    "im = cv2.cvtColor(im, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_folders = [os.path.join('../stamp_detection/stamp_groups/', group) for group in sorted(os.listdir('../stamp_detection/stamp_groups/'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(len(np.unique(classes)), 1, figsize=(8,15))\n",
    "axes = axes.ravel()\n",
    "for template_id, ax in zip(np.unique(classes), axes):\n",
    "    group_folder = group_folders[template_id]\n",
    "    fn = sorted(os.listdir(group_folder))[-1]\n",
    "    temp_img = plt.imread(os.path.join(group_folder, fn))\n",
    "    color = tuple([int(c) for c in (np.array(mpl.colors.BASE_COLORS[class2color[template_id]]) * 255).astype(np.int)])\n",
    "    top, bottom, left, right = [15]*4\n",
    "    temp_img = cv2.copyMakeBorder(temp_img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    ax.imshow(temp_img)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.show()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(im)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_latest_p36]",
   "language": "python",
   "name": "conda-env-pytorch_latest_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
